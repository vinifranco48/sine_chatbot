#!/usr/bin/env python3
"""
Teste para verificar o funcionamento do Agent e integra√ß√£o com chatbot.
"""

import sys
import os
import asyncio
import json
from typing import Dict, Any
from unittest.mock import Mock, patch

# Adicionar o diret√≥rio src ao path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.core.agent import create_compiled_graph, Agent
from src.service.embeddings_services import QueryEmbedder
from src.service.retriever_service import QdrantRetriever
from src.service.llm_service import LLMService
from src.models.embeddings import QueryEmbeddings, Document


class TestAgent:
    """Classe para testar o Agent e suas funcionalidades"""

    def __init__(self):
        self.test_results = {
            'embed_query': False,
            'retrieve_documents': False,
            'generate_response': False,
            'full_pipeline': False
        }

    def setup_mocks(self):
        """Configura os mocks necess√°rios para os testes"""
        # Mock QueryEmbedder
        self.mock_query_embedder = Mock(spec=QueryEmbedder)
        mock_embeddings = QueryEmbeddings(
            dense_embedding=[0.1] * 256,
            sparse_embedding={"tokens": [1, 2, 3], "values": [0.5, 0.3, 0.2]},
            late_interaction_embedding=[[0.1, 0.2], [0.3, 0.4]]
        )
        self.mock_query_embedder.embed_query.return_value = mock_embeddings

        # Mock QdrantRetriever
        self.mock_retriever = Mock(spec=QdrantRetriever)
        mock_documents = [
            Document(
                page_content="Este √© um documento de teste sobre agricultura.",
                metadata={"source": "test1.pdf", "page": 1}
            ),
            Document(
                page_content="Informa√ß√µes sobre cultivo de milho e fertilizantes.",
                metadata={"source": "test2.pdf", "page": 2}
            )
        ]
        self.mock_retriever.search_documents.return_value = mock_documents

        # Mock LLMService
        self.mock_llm_service = Mock(spec=LLMService)
        self.mock_llm_service.generate_response.return_value = (
            "Baseado nas informa√ß√µes fornecidas, posso ajudar com quest√µes sobre agricultura. "
            "O milho √© uma cultura importante que requer cuidados espec√≠ficos com fertilizantes."
        )

    def test_embed_query_node(self):
        """Testa o n√≥ de embedding da query"""
        print("\nüß™ Testando embed_query_node...")

        try:
            from src.core.agent import embed_query_node

            # Estado inicial
            state = Agent(
                query="Como plantar milho?",
                filters=None,
                query_embedding=None,
                retrieved_docs=[],
                context="",
                response=None,
                error=None
            )

            # Executar o n√≥
            result = embed_query_node(state, self.mock_query_embedder)

            # Verificar resultado
            if result.get('query_embedding') and not result.get('error'):
                print("   ‚úÖ embed_query_node funcionou corretamente")
                self.test_results['embed_query'] = True
                return True
            else:
                print(f"   ‚ùå embed_query_node falhou: {result.get('error')}")
                return False

        except Exception as e:
            print(f"   ‚ùå Erro no teste embed_query_node: {e}")
            return False

    def test_retrieve_documents_node(self):
        """Testa o n√≥ de recupera√ß√£o de documentos"""
        print("\nüîç Testando retrieve_documents_node...")

        try:
            from src.core.agent import retrieve_documents_node

            # Estado com embeddings
            mock_embeddings = QueryEmbeddings(
                dense_embedding=[0.1] * 256,
                sparse_embedding={"tokens": [1, 2, 3], "values": [0.5, 0.3, 0.2]},
                late_interaction_embedding=[[0.1, 0.2], [0.3, 0.4]]
            )

            state = Agent(
                query="Como plantar milho?",
                filters=None,
                query_embedding=mock_embeddings,
                retrieved_docs=[],
                context="",
                response=None,
                error=None
            )

            # Executar o n√≥
            result = retrieve_documents_node(state, self.mock_retriever)

            # Verificar resultado
            if (result.get('retrieved_docs') and
                result.get('context') and
                not result.get('error')):
                print("   ‚úÖ retrieve_documents_node funcionou corretamente")
                print(f"   üìÑ Documentos recuperados: {len(result['retrieved_docs'])}")
                self.test_results['retrieve_documents'] = True
                return True
            else:
                print(f"   ‚ùå retrieve_documents_node falhou: {result.get('error')}")
                return False

        except Exception as e:
            print(f"   ‚ùå Erro no teste retrieve_documents_node: {e}")
            return False

    def test_generate_response_node(self):
        """Testa o n√≥ de gera√ß√£o de resposta"""
        print("\nüí¨ Testando generate_response_node...")

        try:
            from src.core.agent import generate_response_node

            # Estado com contexto
            state = Agent(
                query="Como plantar milho?",
                filters=None,
                query_embedding=None,
                retrieved_docs=[],
                context="Este √© um documento sobre agricultura e cultivo de milho.",
                response=None,
                error=None
            )

            # Executar o n√≥
            result = generate_response_node(state, self.mock_llm_service)

            # Verificar resultado
            if result.get('response') and not result.get('error'):
                print("   ‚úÖ generate_response_node funcionou corretamente")
                print(f"   üí¨ Resposta gerada: {result['response'][:100]}...")
                self.test_results['generate_response'] = True
                return True
            else:
                print(f"   ‚ùå generate_response_node falhou: {result.get('error')}")
                return False

        except Exception as e:
            print(f"   ‚ùå Erro no teste generate_response_node: {e}")
            return False

    def test_full_pipeline(self):
        """Testa o pipeline completo do agent"""
        print("\nüöÄ Testando pipeline completo do agent...")

        try:
            # Criar o grafo compilado
            compiled_graph = create_compiled_graph(
                query_embedder=self.mock_query_embedder,
                qdrant_retriever=self.mock_retriever,
                llm_service=self.mock_llm_service
            )

            # Estado inicial
            initial_state = Agent(
                query="Como plantar milho de forma sustent√°vel?",
                filters=None,
                query_embedding=None,
                retrieved_docs=[],
                context="",
                response=None,
                error=None
            )

            # Executar o grafo
            final_state = compiled_graph.invoke(initial_state)

            # Verificar resultado final
            if (final_state.get('response') and
                not final_state.get('error') and
                final_state.get('context')):
                print("   ‚úÖ Pipeline completo funcionou corretamente!")
                print(f"   üí¨ Resposta final: {final_state['response'][:150]}...")
                self.test_results['full_pipeline'] = True
                return True
            else:
                print(f"   ‚ùå Pipeline completo falhou: {final_state.get('error')}")
                return False

        except Exception as e:
            print(f"   ‚ùå Erro no teste do pipeline completo: {e}")
            return False

    def test_chatbot_integration(self):
        """Testa diferentes tipos de perguntas como um chatbot real"""
        print("\nüí≠ Testando integra√ß√£o com chatbot (simula√ß√£o)...")

        test_queries = [
            "Como plantar milho?",
            "Qual √© o melhor fertilizante para soja?",
            "Como controlar pragas na agricultura org√¢nica?",
            "Quando √© a melhor √©poca para plantar tomate?",
            "Como fazer compostagem?"
        ]

        successful_queries = 0

        try:
            compiled_graph = create_compiled_graph(
                query_embedder=self.mock_query_embedder,
                qdrant_retriever=self.mock_retriever,
                llm_service=self.mock_llm_service
            )

            for i, query in enumerate(test_queries, 1):
                print(f"   üó®Ô∏è Teste {i}: {query}")

                initial_state = Agent(
                    query=query,
                    filters=None,
                    query_embedding=None,
                    retrieved_docs=[],
                    context="",
                    response=None,
                    error=None
                )

                try:
                    result = compiled_graph.invoke(initial_state)

                    if result.get('response') and not result.get('error'):
                        print(f"      ‚úÖ Sucesso! Resposta: {result['response'][:80]}...")
                        successful_queries += 1
                    else:
                        print(f"      ‚ùå Falhou: {result.get('error', 'Erro desconhecido')}")

                except Exception as e:
                    print(f"      ‚ùå Exce√ß√£o: {e}")

            success_rate = successful_queries / len(test_queries)
            print(f"\n   üìä Taxa de sucesso: {successful_queries}/{len(test_queries)} ({success_rate*100:.1f}%)")

            if success_rate >= 0.8:
                print("   ‚úÖ Integra√ß√£o com chatbot funcionando bem!")
                return True
            else:
                print("   ‚ö†Ô∏è Integra√ß√£o com chatbot precisa de ajustes")
                return False

        except Exception as e:
            print(f"   ‚ùå Erro no teste de integra√ß√£o: {e}")
            return False

    def run_all_tests(self):
        """Executa todos os testes"""
        print("üéØ === TESTANDO AGENT E CHATBOT ===")

        # Setup
        self.setup_mocks()

        # Executar testes individuais
        tests = [
            ("Embedding da Query", self.test_embed_query_node),
            ("Recupera√ß√£o de Documentos", self.test_retrieve_documents_node),
            ("Gera√ß√£o de Resposta", self.test_generate_response_node),
            ("Pipeline Completo", self.test_full_pipeline),
            ("Integra√ß√£o Chatbot", self.test_chatbot_integration)
        ]

        passed_tests = 0
        total_tests = len(tests)

        for test_name, test_func in tests:
            print(f"\n{'='*50}")
            print(f"üß™ TESTE: {test_name}")
            print(f"{'='*50}")

            if test_func():
                passed_tests += 1

        # Resultado final
        print(f"\n{'='*60}")
        print("üèÅ RESULTADO FINAL DOS TESTES")
        print(f"{'='*60}")
        print(f"‚úÖ Testes passou: {passed_tests}/{total_tests}")
        print(f"üìä Taxa de sucesso: {passed_tests/total_tests*100:.1f}%")

        if passed_tests == total_tests:
            print("üéâ TODOS OS TESTES PASSARAM! O Agent est√° funcionando perfeitamente.")
        elif passed_tests >= total_tests * 0.8:
            print("‚úÖ A maioria dos testes passou. O Agent est√° funcionando bem com pequenos ajustes necess√°rios.")
        else:
            print("‚ö†Ô∏è V√°rios testes falharam. O Agent precisa de corre√ß√µes significativas.")

        print("\nüìã Detalhes dos resultados:")
        for component, status in self.test_results.items():
            status_icon = "‚úÖ" if status else "‚ùå"
            print(f"   {status_icon} {component}")

        return passed_tests / total_tests


def main():
    """Fun√ß√£o principal para executar os testes"""
    tester = TestAgent()
    success_rate = tester.run_all_tests()

    # Exit code baseado no resultado
    exit_code = 0 if success_rate >= 0.8 else 1
    sys.exit(exit_code)


if __name__ == "__main__":
    main()